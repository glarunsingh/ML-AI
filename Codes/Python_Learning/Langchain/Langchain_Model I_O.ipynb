{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd2f7d65-3002-4b8f-bebc-7a43b583b989",
   "metadata": {},
   "source": [
    "### Installing langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27e684e1-51ef-4cc0-b46f-01048bf70830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install langchain\n",
    "\n",
    "#For conda installation\n",
    "#conda install langchain -c conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17fb3b4-f649-4d93-b13a-29287c3afdf8",
   "metadata": {},
   "source": [
    "### LLM CHAINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c6f056f-dd94-46b7-a6c7-17e95eff7baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPENAI \n",
    "\n",
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade6abe2-e6e8-4e54-bf62-6c4da02a9edf",
   "metadata": {},
   "source": [
    "### With OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a066583-3b1c-4242-9829-021eea4bf2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45476933-91fa-4dcf-a187-d242f236a267",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e97fc00f-084e-421b-b4b2-ea23d4df5a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f607d4d8-b895-4dc3-97dc-6eefcb6d1c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Langsmith can help with testing by providing tools and frameworks that enable automated testing of software applications. This can include unit testing, integration testing, and end-to-end testing. Langsmith's tools can also help with performance testing, security testing, and regression testing. Additionally, Langsmith can provide services for test automation, test case design, and test script development to help streamline the testing process and ensure that software applications are thoroughly tested before deployment.\" response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 15, 'total_tokens': 103}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None} id='run-03ed1787-43b5-4858-982e-ac469333b07a-0'\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59fb66a9-faa7-4d71-872c-3820f4d018eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith can help with testing by providing tools and frameworks that enable automated testing of software applications. This can include unit testing, integration testing, and end-to-end testing. Langsmith's tools can also help with performance testing, security testing, and regression testing. Additionally, Langsmith can provide services for test automation, test case design, and test script development to help streamline the testing process and ensure that software applications are thoroughly tested before deployment.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2024c3f7-6a8c-4f74-9fa7-c51e13357d79",
   "metadata": {},
   "source": [
    "We can also guide its response with a prompt template. Prompt templates convert raw user input to better input to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d33112f7-07f5-44f7-bcf4-74880a764f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")]\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cba8ce12-a771-4e0d-bd2d-8ccf8d749671",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fecc84ef-9767-4ef4-8356-557072226be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith is a powerful tool that can greatly assist with testing in various ways. Here are some ways in which Langsmith can help with testing:\\n\\n1. **Automated Testing:** Langsmith can be used to write automated tests for your software applications. By leveraging its language processing capabilities, you can create sophisticated tests that mimic user interactions and validate the functionality of your applications.\\n\\n2. **Natural Language Testing:** Langsmith allows you to write test cases in natural language, making it easier for non-technical stakeholders to understand and contribute to the testing process. This can improve communication and collaboration within your team.\\n\\n3. **Test Data Generation:** Langsmith can help generate test data by analyzing and understanding the structure of your data models. This can save time and effort in creating realistic test data sets for your applications.\\n\\n4. **Regression Testing:** With Langsmith, you can easily create and maintain regression test suites that ensure new code changes do not introduce unintended consequences or break existing functionality.\\n\\n5. **Integration Testing:** Langsmith can be used to automate integration testing by simulating interactions between different components of your applications. This can help identify issues early in the development lifecycle.\\n\\n6. **Performance Testing:** Langsmith can assist in performance testing by generating complex test scenarios and measuring the response times of your applications under different conditions.\\n\\nOverall, Langsmith can streamline the testing process, improve test coverage, and enhance the overall quality of your software applications.', response_metadata={'token_usage': {'completion_tokens': 286, 'prompt_tokens': 27, 'total_tokens': 313}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-4daa0f52-47f8-4645-aaa1-0e744d511a59-0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbaadde-dd31-4999-993c-097b29f07fab",
   "metadata": {},
   "source": [
    "*The output of a ChatModel (and therefore, of this chain) is a message. However, it's often much more convenient to work with strings. Let's add a simple output parser to convert the chat message to a string.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0a31b34-b04e-4e66-9ac3-03b0b37cc6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "outputparser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "830c9831-c894-47a7-b69c-0851f8132d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | outputparser\n",
    "\n",
    "response = chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee11e46a-78b8-49b4-9c5a-147b56d0f80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith can be a valuable tool for testing in several ways:\n",
      "\n",
      "1. **Automation Testing**: Langsmith can be used to automate the generation of test cases for a variety of scenarios. By specifying the grammar and rules for the input data, Langsmith can generate a large number of test cases quickly and efficiently.\n",
      "\n",
      "2. **Boundary Testing**: Langsmith can be used to generate test cases that cover boundary conditions of the input data. This can help in testing the robustness of the system and uncovering potential edge cases that may not have been considered otherwise.\n",
      "\n",
      "3. **Regression Testing**: Langsmith can be used to generate test cases for regression testing. By reusing the same grammar and rules, Langsmith can generate a consistent set of test cases to be run each time the system is updated or changed.\n",
      "\n",
      "4. **Load Testing**: Langsmith can be used to generate a large number of test cases to simulate heavy loads on the system. By generating realistic input data, Langsmith can help in identifying performance bottlenecks and scalability issues.\n",
      "\n",
      "5. **Exploratory Testing**: Langsmith can be used to generate random test cases to explore the behavior of the system. By generating diverse input data, Langsmith can help in uncovering unexpected issues and improving the overall quality of the system.\n",
      "\n",
      "Overall, Langsmith can be a powerful tool for testing by automating the generation of test cases, covering boundary conditions, facilitating regression testing, simulating heavy loads, and enabling exploratory testing.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92d2e5a-321b-42d9-87d8-8d4c5d7f9483",
   "metadata": {},
   "source": [
    "### with Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89e595fb-434e-442d-b147-b19fab030718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fdfefb7-ce1d-48fe-ae57-ed19a2305b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Setting Environment variable\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-07-01-preview\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = 'https://dskumar.openai.azure.com/'\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] =\"62855d6dd08945819bf83aee0c104127\"\n",
    "os.environ[\"DEPLOYMENT_NAME\"] =\"DskumarDeployment\"\n",
    "os.environ['OPENAI_TYPE']=\"Azure\"\n",
    "os.environ[\"LLM_MODEL\"] = \"gpt-35-turbo-16k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4082d9a-9ecf-476c-956f-5d53b67787fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of Azure OpenAI\n",
    "\n",
    "azurellm = AzureChatOpenAI(\n",
    "    deployment_name=os.getenv(\"DEPLOYMENT_NAME\"),openai_api_type='Azure',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9813555-8324-4177-af02-f1ce05e4f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage,SystemMessage,HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2566bd4-9e81-40fc-8523-76898844d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the LLM\n",
    "result=azurellm.invoke([HumanMessage(content=\"Tell me about langchain\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcca4139-f2a8-4d0a-87bb-531c2081fcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LangChain is a blockchain-based language learning platform that aims to revolutionize the way people learn languages. It leverages the power of blockchain technology to create a decentralized ecosystem where language learners and tutors can connect and engage in language learning activities.\\n\\nThe platform offers various features and tools to facilitate language learning. Users can create profiles and specify their language learning goals, interests, and proficiency levels. They can then browse through the available tutors who match their requirements and choose the one that suits their needs.\\n\\nLangChain provides a secure and transparent payment system using cryptocurrencies. Users can pay for language lessons using the platform's native token, eliminating the need for traditional payment methods and reducing transaction costs.\\n\\nAdditionally, LangChain employs smart contracts to ensure fair and reliable transactions between learners and tutors. These contracts outline the terms and conditions of the tutoring sessions, including the duration, pricing, and cancellation policies. This automated process helps build trust and accountability within the platform.\\n\\nThe platform also incorporates gamification elements to make language learning more engaging and enjoyable. Learners can earn rewards and achievements as they progress in their language learning journey, motivating them to continue practicing and improving their skills.\\n\\nLangChain aims to create a global community of language learners and tutors, breaking down barriers and enabling seamless cross-cultural communication. It provides a platform for learners to immerse themselves in different languages and cultures, connecting with tutors from around the world.\\n\\nOverall, LangChain seeks to disrupt the traditional language learning industry by offering a decentralized and efficient platform that empowers learners and tutors. By harnessing the benefits of blockchain technology, it aims to make language learning more accessible, affordable, and interactive for everyone.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131a56a-3a52-4e2f-bad7-ad4780e35996",
   "metadata": {},
   "source": [
    "# Model I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80cc4014-9d41-459b-b73a-ca5ef089e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from secret_key import openapi_key\n",
    "os.environ['OPENAI_API_KEY'] = openapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2b5fd4d-660b-4d20-a21f-e12a0df64b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(openapi_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5a4d64b-e7b1-4a3b-83dc-64a52c811cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "azurellm = AzureChatOpenAI(deployment_name=os.getenv(\"DEPLOYMENT_NAME\"),openai_api_type='Azure')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c61ca5f-e66b-468b-b488-0e1e15f7fd8a",
   "metadata": {},
   "source": [
    "**_Both llm and chat_model are objects that represent configuration for a particular model. You can initialize them with parameters like temperature and others, and pass them around. The main difference between them is their input and output schemas. The LLM objects take string as input and output string. The ChatModel objects take a list of messages as input and output a message._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bbe9a97-e2ff-48a0-b96f-073f3daf4605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "#llm = llm.invoke(text)\n",
    "# >> Feetful of Fun\n",
    "\n",
    "#chat = chat_model.invoke(messages)\n",
    "# >> AIMessage(content=\"Socks O'Color\")\n",
    "\n",
    "azurellms = azurellm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc583a1a-2f70-4dbf-b000-ef6c7be3190a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ColorfulSox Co.' response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 22, 'total_tokens': 28}, 'model_name': 'gpt-35-turbo-16k', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-ede5e4fa-dc0e-4e52-a4dd-4cb9a51599e3-0'\n"
     ]
    }
   ],
   "source": [
    "print(azurellms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8619cc30-5afc-4a2d-a65f-19825cf67478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='RainbowSole Socks' response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 22, 'total_tokens': 28}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None} id='run-d2b84609-7830-4272-9e44-9296c7b94ed5-0'\n"
     ]
    }
   ],
   "source": [
    "print(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8e47fa-3ef2-4e17-bfe0-66033bd2a2d2",
   "metadata": {},
   "source": [
    "### Prompt Templates\n",
    "\n",
    "A prompt for a language model is a set of instructions or input provided by a user to guide the model's response, helping it understand the context and generate relevant and coherent language-based output, such as answering questions, completing sentences, or engaging in a conversation.\n",
    "\n",
    "Typically, language models expect the prompt to either be a string or else a list of chat messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d37c8802-6ae0-4afa-984d-63b320f6123e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "prompt_template.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1b8922-d3a6-4b19-9b88-bcbc8cf32383",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate\n",
    "\n",
    "The prompt to chat models/ is a list of chat messages.\r\n",
    "\r\n",
    "Each chat message is associated with content, and an additional parameter called role. For example, in the OpenAI Chat Completions API, a chat message can be associated with an AI assistant, a human or a system role.\r\n",
    "\r\n",
    "Create a chat prompt template like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfdb0be8-e7b4-40d8-8514-8271b758c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dccf85a-1a26-4a6c-be60-6636341cd4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage,SystemMessage,HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f732d54-0ee0-46ff-91cb-8d5075ba9890",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (2899999032.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[29], line 14\u001b[1;36m\u001b[0m\n\u001b[1;33m    response = client.ainvoke(  begin_conversation(\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of Azure OpenAI\n",
    "\n",
    "client = AzureChatOpenAI(\n",
    "    deployment_name=os.getenv(\"DEPLOYMENT_NAME\"),openai_api_type='Azure',\n",
    ")\n",
    "\n",
    "#client.invoke( input=\"gpt-3.5-turbo\",    messages=[\n",
    "#        {\"role\": \"system\", \"content\": \"You are a helpful AI bot. Your name is Bob.\"},\n",
    " #       {\"role\": \"user\", \"content\": \"Hello, how are you doing?\"},\n",
    "  #      {\"role\": \"assistant\", \"content\": \"I'm doing well, thanks!\"},\n",
    "  #      {\"role\": \"user\", \"content\": \"What is your name?\"},\n",
    "   # ],)\n",
    "\n",
    "response = client.begin_conversation(\n",
    "    model=\"gpt-35-turbo-16k\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, how are you doing?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"I'm doing well, thanks!\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is your name?\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "conversation_result = response.result()\n",
    "for message in conversation_result.messages:\n",
    "    print(f\"{message.role}: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f326ec-33ab-46d3-876e-edac77b85449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3295477f-9c5b-417d-821e-8be395cd370a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
