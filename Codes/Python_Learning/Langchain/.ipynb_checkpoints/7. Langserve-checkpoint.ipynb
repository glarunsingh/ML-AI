{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cbddf70-dbb8-4db0-9556-9221554b6ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"langserve[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03fd051a-d43e-453a-b296-c4df87297197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U langchain-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b21adae7-0787-4b30-ab1f-ae2e3c66152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install typer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2571848-7341-45a6-b65e-9b1dd39a531e",
   "metadata": {},
   "source": [
    "LangServe helps developers deploy LangChain runnables and chains as a REST API.\n",
    "\n",
    "This library is integrated with FastAPI and uses pydantic for data validation.\n",
    "\n",
    "In addition, it provides a client that can be used to call into runnables deployed on a server. A JavaScript client is available in LangChain.js.gServe Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e47c9-46a7-47ec-bd19-e5b2ad25cc5f",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "- Input and Output schemas automatically inferred from your LangChain object, and enforced on every API call, with rich error messages\n",
    "- API docs page with JSONSchema and Swagger (insert example link)\n",
    "- Efficient /invoke, /batch and /stream endpoints with support for many concurrent requests on a single server\n",
    "- /stream_log endpoint for streaming all (or some) intermediate steps from your chain/agent\n",
    "- new as of 0.0.40, supports /stream_events to make it easier to stream without needing to parse the output of /stream_log.\n",
    "- Playground page at /playground/ with streaming output and intermediate steps\n",
    "- Built-in (optional) tracing to LangSmith, just add your API key (see Instructions)\n",
    "- All built with battle-tested open-source Python libraries like FastAPI, Pydantic, uvloop and asyncio.\n",
    "- Use the client SDK to call a LangServe server as if it was a Runnable running locally (or call the HTTP API directly)\n",
    "- LangServe Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55b1b0b1-cc3c-49f0-820b-10e3bda34806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from fastapi import FastAPI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatAnthropic, ChatOpenAI\n",
    "from langserve import add_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d46dee0-d541-454c-8fe9-e59da1c589aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI(\n",
    "    title=\"LangChain Server\",\n",
    "    version=\"1.0\",\n",
    "    description=\"A simple api server using Langchain's Runnable interfaces\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "836279a8-5df1-4dfd-bd91-2787239677d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Setting Environment variable\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2023-07-01-preview\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = 'https://dskumar.openai.azure.com/'\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] =\"62855d6dd08945819bf83aee0c104127\"\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] =\"DskumarDeployment\"\n",
    "os.environ['OPENAI_TYPE']=\"Azure\"\n",
    "os.environ[\"LLM_MODEL\"] = \"gpt-35-turbo-16k\"\n",
    "os.environ[\"LLM_EMBEDDING_MODEL\"] = \"dskumar-text-embedding-ada-002\"\n",
    "\n",
    "from langchain_core.messages import AIMessage,SystemMessage,HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "azurechatmodel = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b934677e-7957-4fb7-bbc4-25f710d54849",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_routes(\n",
    "    app,\n",
    "    azurechatmodel,\n",
    "    path=\"/azureopenai\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a585be1f-0d46-4522-a8f6-ddff9e8870ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a essay about {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "083eed82-b70c-4ce3-bdfe-15082a89adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_routes(\n",
    "    app,\n",
    "    prompt | azurechatmodel,\n",
    "    path=\"/essay\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd25f236-968c-4264-987c-44989f5e665e",
   "metadata": {},
   "source": [
    "This below code will work in VS code, However, its getting error in Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ba71759-e0d9-4c16-bddf-902d9745003a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01muvicorn\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[43muvicorn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocalhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\uvicorn\\main.py:587\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[0;32m    585\u001b[0m     Multiprocess(config, target\u001b[38;5;241m=\u001b[39mserver\u001b[38;5;241m.\u001b[39mrun, sockets\u001b[38;5;241m=\u001b[39m[sock])\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m     \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39muds \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(config\u001b[38;5;241m.\u001b[39muds):\n\u001b[0;32m    589\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(config\u001b[38;5;241m.\u001b[39muds)  \u001b[38;5;66;03m# pragma: py-win32\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\uvicorn\\server.py:61\u001b[0m, in \u001b[0;36mServer.run\u001b[1;34m(self, sockets)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: Optional[List[socket\u001b[38;5;241m.\u001b[39msocket]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msetup_event_loop()\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\asyncio\\runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "\n",
    "    uvicorn.run(app, host=\"localhost\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72083cfd-1303-410c-9ba0-833fe0ba899d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nest_asyncio in c:\\users\\janu\\appdata\\roaming\\python\\python311\\site-packages (1.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c7ebb9a-c4db-4b57-86c0-7734a1bfbff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [23508]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " __          ___      .__   __.   _______      _______. _______ .______     ____    ____  _______\n",
      "|  |        /   \\     |  \\ |  |  /  _____|    /       ||   ____||   _  \\    \\   \\  /   / |   ____|\n",
      "|  |       /  ^  \\    |   \\|  | |  |  __     |   (----`|  |__   |  |_)  |    \\   \\/   /  |  |__\n",
      "|  |      /  /_\\  \\   |  . `  | |  | |_ |     \\   \\    |   __|  |      /      \\      /   |   __|\n",
      "|  `----./  _____  \\  |  |\\   | |  |__| | .----)   |   |  |____ |  |\\  \\----.  \\    /    |  |____\n",
      "|_______/__/     \\__\\ |__| \\__|  \\______| |_______/    |_______|| _| `._____|   \\__/     |_______|\n",
      "\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m Playground for chain \"/azureopenai/\" is live at:\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m  │\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m  └──> /azureopenai/playground/\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m Playground for chain \"/essay/\" is live at:\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m  │\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m  └──> /essay/playground/\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m\n",
      "\u001b[1;32;40mLANGSERVE:\u001b[0m See all available routes at /docs/\n",
      "\n",
      "INFO:     ::1:52753 - \"GET / HTTP/1.1\" 404 Not Found\n",
      "INFO:     ::1:52754 - \"GET /azureopenai/ HTTP/1.1\" 404 Not Found\n",
      "INFO:     ::1:52754 - \"GET /azureopenai/ HTTP/1.1\" 404 Not Found\n",
      "INFO:     ::1:52760 - \"GET /azureopenai/playground/ HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:52760 - \"GET /azureopenai/playground/assets/index-dbc96538.js HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:52766 - \"GET /azureopenai/playground/assets/index-52e8ab2f.css HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:52766 - \"GET /azureopenai/playground/favicon.ico HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:52766 - \"GET /azureopenai/playground/favicon.ico HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:52772 - \"GET /essay/playground/ HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:52772 - \"GET /essay/playground/assets/index-dbc96538.js HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:52773 - \"GET /essay/playground/assets/index-52e8ab2f.css HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:52773 - \"GET /essay/playground/favicon.ico HTTP/1.1\" 200 OK\n",
      "INFO:     ::1:52778 - \"POST /essay/stream_log HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [23508]\n"
     ]
    }
   ],
   "source": [
    "import uvicorn\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply the nest_asyncio patch to allow nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"localhost\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe389f7-c1e1-4cfb-8c8a-a43db52e1761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
