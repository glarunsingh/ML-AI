{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "166b8271-5366-48b3-9e53-0a5da9c095f8",
   "metadata": {},
   "source": [
    "# Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33328fb4-f3b8-4e76-83df-73d48663d15f",
   "metadata": {},
   "source": [
    "This section contains higher-level components that combine other arbitrary systems (e.g. external APIs and services) and/or LangChain primitives together.\n",
    "\n",
    "A good primer for this section would be reading the sections on LangChain Expression Language and becoming familiar with constructing sequences via piping and the various primitives offered.\n",
    "\n",
    "The components covered in this section are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca071cb-40f4-4c37-896c-57ad2753ca4f",
   "metadata": {},
   "source": [
    "# 1. Tools\n",
    "\n",
    "Tools provide an interface for LLMs and other components to interact with other systems. Examples include Wikipedia, a calculator, and a Python REPL\n",
    "\n",
    "Tools are interfaces that an agent, chain, or LLM can use to interact with the world. They combine a few things:\r\n",
    "\r\n",
    "The name of the tool\r\n",
    "A description of what the tool is\r\n",
    "JSON schema of what the inputs to the tool are\r\n",
    "The function to call\r\n",
    "Whether the result of a tool should be returned directly to the user\r\n",
    "It is useful to have all this information because this information can be used to build action-taking systems! The name, description, and JSON schema can be used to prompt the LLM so it knows how to specify what action to take, and then the function to call is equivalent to taking that action.\r\n",
    "\r\n",
    "The simpler the input to a tool is, the easier it is for an LLM to be able to use it. Many agents will only work with tools that have a single string input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edba706c-4b3b-4d1b-99da-08301b0de76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\janu\\appdata\\roaming\\python\\python311\\site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11704 sha256=8f374f006a85cf05d7ac68027c639dd9dde2e69e0080dd9e20763195db143d56\n",
      "  Stored in directory: c:\\users\\janu\\appdata\\local\\pip\\cache\\wheels\\8f\\ab\\cb\\45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4959710-bec6-4811-ba4c-1a0d7c6763cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2a269ae-c42e-416c-8c25-eacbec4bd131",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16b393a1-2b81-4d61-8de9-6a4338c0cd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2067642-b59a-4f55-8da3-ee9e030511f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad7c2ee-f58b-4904-ab08-1f87c855855b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'title': 'Query', 'type': 'string'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975254ea-54b1-463d-9197-133d9f97d998",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run({\"query\": \"langchain\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e653e97a-a1a1-4dba-9e93-c6c0ba7429e7",
   "metadata": {},
   "source": [
    "### Yahoo Finance tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f0e71d1-04f9-4bfb-85e1-3e7a3fd56c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet  yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93088170-4999-4f9c-b9a5-18909a4d12d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Setting Environment variable\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2023-07-01-preview\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = 'https://dskumar.openai.azure.com/'\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] =\"62855d6dd08945819bf83aee0c104127\"\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] =\"DskumarDeployment\"\n",
    "os.environ['OPENAI_TYPE']=\"Azure\"\n",
    "os.environ[\"LLM_MODEL\"] = \"gpt-35-turbo-16k\"\n",
    "os.environ[\"LLM_EMBEDDING_MODEL\"] = \"dskumar-text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed2687b-e01f-4326-a592-bb62cd2e809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage,SystemMessage,HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings ##embedding type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c684b4-13f2-406f-8b17-23a52d73ffef",
   "metadata": {},
   "source": [
    "### Defining a chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb62477c-808a-4243-9877-cf04d35cabdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca3609e-2b61-4ce1-9493-24fe16da4b38",
   "metadata": {},
   "source": [
    "### Defining a embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "983a5506-9a9e-44a5-b05b-f5ede3365ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(model = os.environ[\"LLM_EMBEDDING_MODEL\"],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3564ad5-fcca-449f-8dfe-6af8af2e77ba",
   "metadata": {},
   "source": [
    "### Defining Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7220c316-3918-4fc1-80f1-e34cdc03b620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JANU\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
    "\n",
    "tools = [YahooFinanceNewsTool()]\n",
    "agent_chain = initialize_agent(tools,chat_model,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d3f07f0-52cc-4e77-940a-e24d9456aa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should check the latest news about Microsoft stocks.\n",
      "Action: yahoo_finance_news\n",
      "Action Input: MSFT\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNasdaq 100 Breaks 3-Day Losing Streak As Tech Stocks Rebound Ahead Of Earnings Week\n",
      "The Nasdaq 100 index, as tracked by the Invesco QQQ Trust (NASDAQ:QQQ), ended Monday 1% higher, breaking a three-day losing streak as traders prepare for a crucial week of earnings reports from some of the tech sector’s most influential names. This week’s earnings lineup features four Magnificent Seven giants like Tesla Inc. (NASDAQ:TSLA), which will report on Tuesday, followed by Meta Platforms Inc. (NASDAQ:META) on Wednesday, and both Microsoft Corp. (NYSE:MSFT) and Alphabet Inc. (NASDAQ:GOOGL\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mMicrosoft stocks are performing well today as the Nasdaq 100 index ended 1% higher.\n",
      "Final Answer: Microsoft stocks ended higher today.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What happens today with Microsoft stocks?',\n",
       " 'output': 'Microsoft stocks ended higher today.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(\n",
    "    \"What happens today with Microsoft stocks?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3147f6b8-81e5-4ca4-8955-4cd831985603",
   "metadata": {},
   "source": [
    "\n",
    "To see more - https://python.langchain.com/docs/integrations/tools/\n",
    "\n",
    "We can also create a custom tool based on customer requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53087ca-6670-42d3-9b16-c9f1ed1dfb55",
   "metadata": {},
   "source": [
    "# 2. Agents \n",
    "\n",
    "Agents use a language model to decide actions to take, often defined by a tool. They require an executor, which is the runtime for the agent. The executor is what actually calls the agent, executes the tools it chooses, passes the action outputs back to the agent, and repeats. The agent is responsible for parsing output from the previous results and choosing the next steps.\n",
    "\n",
    "The core idea of agents is to use a language model to choose a sequence of actions to take. In chains, a sequence of actions is hardcoded (in code). In agents, a language model is used as a reasoning engine to determine which actions to take and in which order.\n",
    "\n",
    "let’s build an agent that has two tools: one to look things up online, and one to look up specific data that we’ve loaded into a index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a214d06d-2a95-4b5e-8d3d-fa44245981bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U langchain-community tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a1d223b-64cd-4935-8c6a-857b1685ad6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "163e4f3a-9e57-4f7c-bfd4-cca42be3afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "063a30e7-84cc-469c-ba8f-3714eeb05846",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88793e0e-6738-4a88-bcd7-fa84f3a99ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = search.invoke(\"what is today's weather in Chennai with the date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbe94fe6-0c64-415e-88af-b61c8a2de2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Chennai', 'region': 'Tamil Nadu', 'country': 'India', 'lat': 13.08, 'lon': 80.28, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1713862679, 'localtime': '2024-04-23 14:27'}, 'current': {'last_updated_epoch': 1713861900, 'last_updated': '2024-04-23 14:15', 'temp_c': 37.0, 'temp_f': 98.6, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 11.9, 'wind_kph': 19.1, 'wind_degree': 130, 'wind_dir': 'SE', 'pressure_mb': 1006.0, 'pressure_in': 29.71, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 42, 'cloud': 25, 'feelslike_c': 48.2, 'feelslike_f': 118.8, 'vis_km': 7.0, 'vis_miles': 4.0, 'uv': 8.0, 'gust_mph': 19.0, 'gust_kph': 30.6}}\"}, {'url': 'https://www.timeanddate.com/weather/india/chennai/hourly', 'content': 'Hour-by-Hour Forecast for Chennai, Tamil Nadu, India. Time/General. Weather. Time Zone. DST Changes. Sun & Moon. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Currently: 86 °F. Passing clouds.'}, {'url': 'https://weather.com/en-IN/india/news/video/watch-latest-india-weather-forecast-april-23-2024', 'content': \"23 April 2024. India's weather forecast, including the temperature and rainfall predictions, for Tuesday. Now Playing. WATCH: Latest India Weather Forecast: April 23 01:00. Next Up.\"}, {'url': 'https://world-weather.info/forecast/india/chennai_1/april-2024/', 'content': \"Detailed ⚡ Chennai Weather Forecast for April 2024 - day/night 🌡️ temperatures, precipitations - World-Weather.info ... 23 +90° +84° 24 +90° +84° 25 ... world's temperature today. Russia Aksarka day +9 °F night-13 °F. Chad Bokoro day +117 °F night +88 °F. Services. Support. User agreement;\"}, {'url': 'https://www.msn.com/en-us/sports/other/ipl-2024-weather-update-chennai-weather-report-for-april-23-for-csk-vs-lsg-match/ar-AA1nufVf', 'content': 'The 39th match of the Indian Premier League (IPL) will see the Chennai Super Kings (CSK) lock horns with the Lucknow Super Giants (LSG) at Chepauk on Tuesday, April 23. Both teams have had a ...'}]\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fa2bf4b-d91c-4f0c-9fe5-8c605299cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddf9dd02-5178-4d9b-a01f-187e5bfb0f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings,\n",
    ")\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b10841e8-d966-478f-9242-54b7a0cab466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='# The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={      \"version\": \"1.0.0\",      \"revision_id\": \"beta\"    },)import { Client, Run, Example } from \\'langsmith\\';import { runOnDataset } from \\'langchain/smith\\';import { EvaluationResult } from \\'langsmith/evaluation\\';const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {    description: \"A sample dataset in LangSmith.\"});await client.createExamples({    inputs: [        { postfix: \"to LangSmith\" },        { postfix: \"to Evaluations in LangSmith\" },    ],    outputs: [        { output: \"Welcome to LangSmith\" },        { output: \"Welcome to Evaluations in LangSmith\" },    ],    datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async ({ run, example }: { run: Run; example?:', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'Introduction', 'language': 'en'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"how to upload a dataset\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d8fbde4-911f-4b32-b9b3-b0a1cb5ffe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7c120bb-5c3e-4ce4-995f-df6af9e83580",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6827bd2a-a4b5-4fe7-ac4b-84f6da0ba831",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911d949b-58c1-4e97-9c21-f1a6cb4b6714",
   "metadata": {},
   "source": [
    "## Create the agent\n",
    "\n",
    "Now that we have defined the tools, we can create the agent. We will be using an OpenAI Functions agent - for more information on this type of agent, as well as other options, see this guide.\n",
    "\n",
    "First, we choose the LLM we want to be guiding the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "990c4660-60d3-4436-b5f4-d5e3d8909d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "chat_model = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f02b6b3d-7cf3-46e8-90fe-424ae887bba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.15-py3-none-any.whl.metadata (621 bytes)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchainhub) (2.31.0)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchainhub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchainhub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchainhub) (2024.2.2)\n",
      "Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
      "Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: types-requests, langchainhub\n",
      "Successfully installed langchainhub-0.1.15 types-requests-2.31.0.20240406\n"
     ]
    }
   ],
   "source": [
    "!pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea803747-93fd-44d3-8329-c1c082e7ccf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# Get the prompt to use - you can modify this! - https://smith.langchain.com/hub/hwchase17/openai-functions-agent\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17b32e3d-ae76-4026-aa8d-2c41147c305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(chat_model, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc788c0f-a42f-45c9-ab3b-cb84febf27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f5ef90-0209-4298-9201-5ac69bf76773",
   "metadata": {},
   "source": [
    "### Run an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "236e505b-2093-4a51-b284-c2077f1ee1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a52948eb-e20b-4369-9ef1-299ba2f59d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'LangSmith testing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mGetting started with LangSmith | ğŸ¦œï¸�ğŸ› ï¸� LangSmith\n",
      "\n",
      "Skip to main contentLangSmith API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookQuick StartOn this pageGetting started with LangSmithIntroductionâ€‹LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!Install LangSmithâ€‹We offer Python and Typescript SDKs for all your LangSmith needs.PythonTypeScriptpip install -U langsmithyarn add langchain langsmithCreate an API keyâ€‹To create an API key head to the setting pages. Then click Create API Key.Setup your environmentâ€‹Shellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>Log your first traceâ€‹We provide multiple ways to\n",
      "\n",
      "learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resourcesâ€‹LangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!FAQâ€‹How do I migrate projects between organizations?â€‹Currently we do not support project migration betwen\n",
      "\n",
      "issues, please reach out to us at support@langchain.dev.My team deals with sensitive data that cannot be logged. How can I ensure that only my team can access it?â€‹If you are interested in a private deployment of LangSmith or if you need to self-host, please reach out to us at sales@langchain.dev. Self-hosting LangSmith requires an annual enterprise license that also comes with support and formalized access to the LangChain team.Was this page helpful?NextUser GuideIntroductionInstall LangSmithCreate an API keySetup your environmentLog your first traceCreate your first evaluationNext StepsAdditional ResourcesFAQHow do I migrate projects between organizations?Why aren't my runs aren't showing up in my project?My team deals with sensitive data that cannot be logged. How can I ensure that only my team can access it?CommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright Â© 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith can help with testing by providing a platform for building production-grade language model applications. It allows you to closely monitor and evaluate your application, ensuring that it performs as expected. LangSmith offers tracing capabilities to track the behavior of your application, evaluation capabilities to assess its performance, and prompt management tools for efficient testing. Additionally, LangSmith supports workflows at each stage of the language model application lifecycle, making it easier to test and iterate on your application.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'output': 'LangSmith can help with testing by providing a platform for building production-grade language model applications. It allows you to closely monitor and evaluate your application, ensuring that it performs as expected. LangSmith offers tracing capabilities to track the behavior of your application, evaluation capabilities to assess its performance, and prompt management tools for efficient testing. Additionally, LangSmith supports workflows at each stage of the language model application lifecycle, making it easier to test and iterate on your application.'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53523d41-010a-47ae-82d3-26eb4366366b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in Chennai'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Chennai', 'region': 'Tamil Nadu', 'country': 'India', 'lat': 13.08, 'lon': 80.28, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1713862999, 'localtime': '2024-04-23 14:33'}, 'current': {'last_updated_epoch': 1713862800, 'last_updated': '2024-04-23 14:30', 'temp_c': 37.0, 'temp_f': 98.6, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 11.9, 'wind_kph': 19.1, 'wind_degree': 130, 'wind_dir': 'SE', 'pressure_mb': 1006.0, 'pressure_in': 29.71, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 42, 'cloud': 25, 'feelslike_c': 48.2, 'feelslike_f': 118.8, 'vis_km': 7.0, 'vis_miles': 4.0, 'uv': 8.0, 'gust_mph': 19.0, 'gust_kph': 30.6}}\"}, {'url': 'https://www.mykhel.com/cricket/csk-vs-lsg-ipl-2024-ma-chidambaram-stadium-pitch-report-chennai-weather-forecast-live-streaming-278465.html', 'content': 'IPL 2024 Full Coverage | IPL 2024 Points Table | IPL 2024 Stats. Chennai Weather Report on Tuesday, April 23. No chances of rain in Chennai on Tuesday, April 23. With a humidity level of 70 percent, the temperature in Chennai will hover around 35 degree celsius. The wind speed at the MA Chidambaram Stadium will be close to 21 km/h.'}, {'url': 'https://www.accuweather.com/en/in/chennai/206671/april-weather/206671', 'content': 'Get the monthly weather forecast for Chennai, Tamil Nadu, India, including daily high/low, historical averages, to help you plan ahead.'}, {'url': 'https://www.weather25.com/asia/india/tamil-nadu/chennai?page=month&month=April', 'content': 'The temperatures in Chennai during April are extremely high, between 82°F and hot as 95°F, drinking water regularly is advisable. You can expect a few rainy days in Chennai during April, but usually the weather is comfortable in April. Our weather forecast can give you a great sense of what weather to expect in Chennai in April 2024.'}, {'url': 'https://www.sportskeeda.com/cricket/news-ipl-2024-weather-update-chennai-weather-report-april-23-csk-vs-lsg-match', 'content': 'The 39th match of the Indian Premier League (IPL) will see the Chennai Super Kings (CSK) lock horns with the Lucknow Super Giants (LSG) at Chepauk on Tuesday, April 23. Both teams have had a ...'}]\u001b[0m\u001b[32;1m\u001b[1;3mThe current weather in Chennai is partly cloudy with a temperature of 37°C (98.6°F). The wind speed is 19.1 km/h coming from the southeast. The humidity is 42% and the visibility is 7.0 km.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats the weather in chennai?',\n",
       " 'output': 'The current weather in Chennai is partly cloudy with a temperature of 37°C (98.6°F). The wind speed is 19.1 km/h coming from the southeast. The humidity is 42% and the visibility is 7.0 km.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"whats the weather in chennai?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ddf7f0-11ec-4436-888e-e07bfb4540d7",
   "metadata": {},
   "source": [
    "### Adding in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a1990e1-fcf6-40c8-972f-3e4acb8cb831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! my name is bob',\n",
       " 'chat_history': [],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we pass in an empty list of messages for chat_history because it is the first message in the chat\n",
    "agent_executor.invoke({\"input\": \"hi! my name is bob\", \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cb1d840-5149-4d28-b894-1b40766dc192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6eca2d22-db07-4167-ae4e-1ff06d889c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Bob.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='hi! my name is bob'),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'input': \"what's my name?\",\n",
       " 'output': 'Your name is Bob.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"hi! my name is bob\"),\n",
    "            AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        ],\n",
    "        \"input\": \"what's my name?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ced6196-e98f-48bc-b6ee-b66ead0928f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "588cf045-f2de-447e-80ac-127dd83e6b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cce1564-4bc9-4078-aaaa-77af718186df",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d3970ce-c152-41b7-b041-41ecb7aaa6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"hi! I'm bob\",\n",
       " 'chat_history': [],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"hi! I'm bob\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18bd22d2-761f-4fd5-bde5-29dbc6580a5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Bob.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's my name?\",\n",
       " 'chat_history': [HumanMessage(content=\"hi! I'm bob\"),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'output': 'Your name is Bob.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"what's my name?\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c3daf6-3844-4f85-bc99-24c504985571",
   "metadata": {},
   "source": [
    "The core idea of agents is to use a language model to choose a sequence of actions to take. In chains, a sequence of actions is hardcoded (in code). In agents, a language model is used as a reasoning engine to determine which actions to take and in which order.\n",
    "\n",
    "There are several key components here: a string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd11387-815f-4694-b814-5665a33b7ab2",
   "metadata": {},
   "source": [
    "## Schema\n",
    "LangChain has several abstractions to make working with agents easy.\n",
    "\n",
    "### 1. AgentAction\n",
    "\n",
    "This is a dataclass that represents the action an agent should take. It has a tool property (which is the name of the tool that should be invoked) and a tool_input property (the input to that tool)\n",
    "\n",
    "### 2. AgentFinish\n",
    "\n",
    "This represents the final result from an agent, when it is ready to return to the user. It contains a return_values key-value mapping, which contains the final agent output. Usually, this contains an output key containing a string that is the agent's response.\n",
    "\n",
    "### 3. Intermediate Steps\n",
    "\n",
    "These represent previous agent actions and corresponding outputs from this CURRENT agent run. These are important to pass to future iteration so the agent knows what work it has already done. This is typed as a List[Tuple[AgentAction, Any]]. Note that observation is currently left as type Any to be maximally flexible. In practice, this is often a string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685f6a42-287b-4a28-bc17-b131dd61f445",
   "metadata": {},
   "source": [
    "## Agent Types\n",
    "This categorizes all the available agents along a few dimensions.\n",
    "\n",
    "### Intended Model Type\n",
    "\n",
    "Whether this agent is intended for Chat Models (takes in messages, outputs message) or LLMs (takes in string, outputs string). The main thing this affects is the prompting strategy used. You can use an agent with a different type of model than it is intended for, but it likely won't produce results of the same quality.\n",
    "\n",
    "### Supports Chat History\n",
    "\n",
    "Whether or not these agent types support chat history. If it does, that means it can be used as a chatbot. If it does not, then that means it's more suited for single tasks. Supporting chat history generally requires better models, so earlier agent types aimed at worse models may not support it.\n",
    "\n",
    "### Supports Multi-Input Tools\n",
    "\n",
    "Whether or not these agent types support tools with multiple inputs. If a tool only requires a single input, it is generally easier for an LLM to know how to invoke it. Therefore, several earlier agent types aimed at worse models may not support them.\n",
    "\n",
    "### Supports Parallel Function Calling\n",
    "\n",
    "Having an LLM call multiple tools at the same time can greatly speed up agents whether there are tasks that are assisted by doing so. However, it is much more challenging for LLMs to do this, so some agent types do not support this.\n",
    "\n",
    "### Required Model Params\n",
    "\n",
    "Whether this agent requires the model to support any additional parameters. Some agent types take advantage of things like OpenAI function calling, which require other model parameters. If none are required, then that means that everything is done via prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7aa13d-76dd-498f-b3f5-5b8fd48c1a91",
   "metadata": {},
   "source": [
    "## Creating a Custom agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f6e1bf9-39c0-4385-b40f-fb9e7e831f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the LLM/Chat Model\n",
    "\n",
    "chat_model = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c94fb93-4165-4eb7-b05a-df846c269aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Defining a tool\n",
    "\n",
    "from langchain.agents import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "get_word_length.invoke(\"abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fa16246-0134-44f0-b03e-90b7b3a94ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assiging the function to an object\n",
    "tools = [get_word_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cadec4d3-14b8-4ef7-ba36-c0bc572ca89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a prompt\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are very powerful assistant, but don't know current events\",\n",
    "        ),\n",
    "        (\"user\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ac5c0f6-e20b-466b-91fe-4fdab8caf26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binding the tool to llm\n",
    "llm_with_tools = chat_model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3dfe2a0-a940-4423-9ed6-3a1cb923a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a chat agent\n",
    "\n",
    "from langchain.agents.format_scratchpad.openai_tools import format_to_openai_tool_messages\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIToolsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ba54697-1cc8-422e-a2d9-713e5dcf0783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating agent executor\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3fa740dc-0263-459f-9b17-e497c372042b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_word_length` with `{'word': 'eudca'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m5\u001b[0m\u001b[32;1m\u001b[1;3mThere are 5 letters in the word \"eudca\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'actions': [ToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_0WnoGyGfwZroxOT6Q2N741NI', 'function': {'arguments': '{\\n  \"word\": \"eudca\"\\n}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-767da9aa-6ab0-4b30-b746-c3389cc4c87b', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_0WnoGyGfwZroxOT6Q2N741NI'}], tool_call_chunks=[{'name': 'get_word_length', 'args': '{\\n  \"word\": \"eudca\"\\n}', 'id': 'call_0WnoGyGfwZroxOT6Q2N741NI', 'index': 0}])], tool_call_id='call_0WnoGyGfwZroxOT6Q2N741NI')],\n",
       "  'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_0WnoGyGfwZroxOT6Q2N741NI', 'function': {'arguments': '{\\n  \"word\": \"eudca\"\\n}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-767da9aa-6ab0-4b30-b746-c3389cc4c87b', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_0WnoGyGfwZroxOT6Q2N741NI'}], tool_call_chunks=[{'name': 'get_word_length', 'args': '{\\n  \"word\": \"eudca\"\\n}', 'id': 'call_0WnoGyGfwZroxOT6Q2N741NI', 'index': 0}])]},\n",
       " {'steps': [AgentStep(action=ToolAgentAction(tool='get_word_length', tool_input={'word': 'eudca'}, log=\"\\nInvoking: `get_word_length` with `{'word': 'eudca'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_0WnoGyGfwZroxOT6Q2N741NI', 'function': {'arguments': '{\\n  \"word\": \"eudca\"\\n}', 'name': 'get_word_length'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-767da9aa-6ab0-4b30-b746-c3389cc4c87b', tool_calls=[{'name': 'get_word_length', 'args': {'word': 'eudca'}, 'id': 'call_0WnoGyGfwZroxOT6Q2N741NI'}], tool_call_chunks=[{'name': 'get_word_length', 'args': '{\\n  \"word\": \"eudca\"\\n}', 'id': 'call_0WnoGyGfwZroxOT6Q2N741NI', 'index': 0}])], tool_call_id='call_0WnoGyGfwZroxOT6Q2N741NI'), observation=5)],\n",
       "  'messages': [FunctionMessage(content='5', name='get_word_length')]},\n",
       " {'output': 'There are 5 letters in the word \"eudca\".',\n",
       "  'messages': [AIMessage(content='There are 5 letters in the word \"eudca\".')]}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#invoking the agent\n",
    "list(agent_executor.stream({\"input\": \"How many letters in the word eudca\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8ed13d5f-89df-42e2-8188-53797236a75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The word \"educa\" has 5 letters.', response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 15, 'total_tokens': 26}, 'model_name': 'gpt-35-turbo-16k', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-6431ed95-e642-4668-a96e-657b11928d86-0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"How many letters in the word educa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f83650-cfad-4b8c-8b11-544f6c7a5fd5",
   "metadata": {},
   "source": [
    "# 3. Chains\n",
    "\n",
    "Chains refer to sequences of calls - whether to an LLM, a tool, or a data preprocessing step. The primary supported way to do this is with LCEL.\n",
    "\n",
    "LCEL is great for constructing your own chains, but it’s also nice to have chains that you can use off-the-shelf. There are two types of off-the-shelf chains that LangChain supports:\n",
    "\n",
    "Chains that are built with LCEL. In this case, LangChain offers a higher-level constructor method. However, all that is being done under the hood is constructing a chain with LCEL.\n",
    "\n",
    "[Legacy] Chains constructed by subclassing from a legacy Chain class. These chains do not use LCEL under the hood but are rather standalone classes.\n",
    "\n",
    "We are working creating methods that create LCEL versions of all chains. We are doing this for a few reasons.\r\n",
    "\r\n",
    "Chains constructed in this way are nice because if you want to modify the internals of a chain you can simply modify the LCEL.\r\n",
    "\r\n",
    "These chains natively support streaming, async, and batch out of the box.\r\n",
    "\r\n",
    "These chains automatically get observability at each step.\r\n",
    "\r\n",
    "This page contains two lists. First, a list of all LCEL chain constructors. Second, a list of all legacy Chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0ace06dc-b952-46a3-9592-9f3df3221c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in c:\\users\\janu\\appdata\\roaming\\python\\python311\\site-packages (0.1.16)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\janu\\appdata\\roaming\\python\\python311\\site-packages (0.0.34)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\janu\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\janu\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in c:\\users\\janu\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (0.1.45)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\janu\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\janu\\appdata\\roaming\\python\\python311\\site-packages (from langchain) (0.1.43)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\janu\\appdata\\roaming\\python\\python311\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\janu\\appdata\\roaming\\python\\python311\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\janu\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\janu\\appdata\\roaming\\python\\python311\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f138c843-dba1-4bbf-90a2-a394280a03b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc6676fa-9251-4a82-be64-89f428c5cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"What are everyone's favorite colors:\\n\\n{context}\")]\n",
    ")\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\n",
    ")\n",
    "chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=\"Jesse loves red but not yellow\"),\n",
    "    Document(page_content = \"Jamal loves green but not as much as he loves orange\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a42f5a25-1669-420f-af6f-73a5c95a3889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Jesse's favorite color is red.\\nJamal's favorite color is orange.\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"context\": docs})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
